---
title: "Pr√°ctica 12: SAM Segmentation - Pretrained vs Fine-tuned"
date: 2025-10-28
---

# Pr√°ctica 12: SAM Segmentation - Pretrained vs Fine-tuned

## Contexto

En esta actividad se trabaj√≥ con el modelo **Segment Anything (SAM)** aplicado al problema de **segmentaci√≥n de √°reas inundadas** usando el dataset p√∫blico **‚ÄúFlood Area Segmentation‚Äù** de Kaggle. Se busc√≥ comparar performance de pretrained SAM zero-shot vs fine-tuned SAM.

El dataset utilizado consta de 290 im√°genes de √°reas inundadas. Estas im√°genes tienen adem√°s m√°scaras de segmentaci√≥n del agua ya que no basta con solo im√°genes sino que se necesita el par imagen-m√°scara. El caso de uso real para este dataset es el monitoreo de inundaciones, la planificaci√≥n de desastres, etc.

---

El flujo general fue:

- Descargar y explorar el dataset (im√°genes satelitales y m√°scaras de agua).
- Evaluar el desempe√±o **zero-shot** del SAM preentrenado usando **point prompts** y **box prompts**.
- Preparar un `Dataset` de PyTorch y `DataLoaders` para entrenamiento.
- Hacer **fine-tuning** de SAM (congelando el image encoder y prompt encoder, entrenando solo el mask decoder).
- Comparar cuantitativamente y visualmente el SAM preentrenado vs el modelo fine-tuneado.
- Analizar casos de fallo antes y despu√©s del fine-tuning.

---

## Objetivos

- Evaluar el rendimiento **pretrained** de SAM en segmentaci√≥n de agua en inundaciones (IoU, Dice, precision, recall).
- Implementar un pipeline completo de **fine-tuning** de SAM sobre el dataset de inundaciones.
- Comparar **point prompts** vs **box prompts** como estrategias de entrada.
- Analizar en qu√© situaciones SAM falla y c√≥mo cambia ese comportamiento tras el fine-tuning.
- Reflexionar sobre la **viabilidad de despliegue** de este sistema en escenarios reales de respuesta a desastres.

---

## Actividades

| Actividad | Tiempo estimado | Resultado esperado |
|------------|----------------|--------------------|
| Preparaci√≥n del entorno y descarga del dataset (Kaggle, instalaci√≥n de librer√≠as) | 20 min | Entorno configurado y dataset disponible en `flood_dataset/` |
| Exploraci√≥n del dataset y visualizaci√≥n de im√°genes + m√°scaras | 20 min | Comprensi√≥n de la estructura del dataset y validaci√≥n de las m√°scaras |
| Evaluaci√≥n del SAM preentrenado con point y box prompts (m√©tricas + gr√°ficos) | 30 min | M√©tricas iniciales (IoU, Dice, Precision, Recall) y visualizaciones de referencia |
| Definici√≥n del `Dataset` de PyTorch, DataLoaders y funciones de p√©rdida (BCE + Dice) | 30 min | Pipeline de datos y p√©rdidas implementado correctamente |
| Configuraci√≥n del fine-tuning (congelar encoders, entrenar mask decoder, optimizer + scheduler) | 20 min | Modelo configurado para entrenamiento eficiente con freeze selectivo |
| Entrenamiento del modelo (varios epochs, registro de curvas de loss e IoU) | 60‚Äì90 min | Modelo fine-tuneado con mejores m√©tricas de validaci√≥n |
| Evaluaci√≥n del modelo fine-tuneado y comparaci√≥n con el pretrained | 30 min | Incrementos cuantitativos (IoU, Dice) y an√°lisis visual de mejoras |
| An√°lisis de failure cases y redacci√≥n de conclusiones / reflexi√≥n | 30 min | Identificaci√≥n de errores persistentes y conclusiones finales documentadas |

---

## Desarrollo

### 1. Preparaci√≥n del entorno y dataset
Se instalaron las librer√≠as necesarias (`segment-anything`, `torch`, `opencv-python`, `albumentations`, etc.) y se descarg√≥ el dataset *Flood Area Segmentation* desde Kaggle mediante la API.  
Las im√°genes se almacenaron en `flood_dataset/Image/` y las m√°scaras binarias en `flood_dataset/Mask/`.

üìå *Librer√≠as instaladas*
```python hl_lines="2 6" linenums="1"
    !pip install -q segment-anything
    !pip install -q opencv-python matplotlib torch torchvision
    !pip install -q albumentations scikit-image
```

üìå *Configuraci√≥n de Kaggle API*
```python hl_lines="2 6" linenums="1"
from google.colab import files
uploaded = files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
```
A continuaci√≥n, se descarg√≥ el dataset **‚ÄúFlood Area Segmentation‚Äù** desde Kaggle y se descomprimi√≥ en la carpeta `flood_dataset/`.

### 2. Carga y an√°lisis del dataset
Una vez descomprimido el dataset, se explor√≥ la estructura de carpetas para identificar correctamente la ubicaci√≥n de im√°genes y m√°scaras. Se encontr√≥ que:

- Las **im√°genes RGB** est√°n en `flood_dataset/Image/`
- Las **m√°scaras de segmentaci√≥n** est√°n en `flood_dataset/Mask/`

Se utiliz√≥ una funci√≥n `load_flood_data` que carga las im√°genes RGB y sus m√°scaras, las convierte a binario y calcula estad√≠sticas del conjunto: tama√±os √∫nicos, ratio de p√≠xeles de agua, etc. Por ejemplo, los tama√±os √∫nicos de im√°genes son 81, mientras que el promedio de ratio de p√≠xeles de agua es de un 42.8% contra un 57.2% del fondo (background).

Se visualizaron ejemplos de pares imagen/m√°scara para verificar consistencia.

üìä *Ejemplos de pares imagen/mask*   
![Setup](./img/p12_masks.png){ width="600" }

### 3. Evaluaci√≥n del SAM preentrenado
Se descarg√≥ el checkpoint `sam_vit_b_01ec64.pth` y se prob√≥ el modelo usando dos tipos de *prompts*:
- **Point prompts:** un punto en la regi√≥n de agua (foreground).
- **Box prompts:** caja delimitadora extra√≠da desde la m√°scara.

En este paso se utilizaron dos funciones clave:

1. `predict_with_point_prompt(predictor, image, point_coords, point_labels)`: Usa un punto dentro de la regi√≥n de agua (foreground) como prompt.

2. `predict_with_box_prompt(predictor, image, box)`: Usa una bounding box extra√≠da desde la m√°scara ground truth como prompt.

Se calcularon m√©tricas (`IoU`, `Dice`, `Precision`, `Recall`) con funciones personalizadas. Los resultados mostraron un rendimiento inicial bastante bueno pero con fallas en detecci√≥n de bordes, reflejos y sombras.

üìä *Ejemplo de imagen + point prompt*   
![Setup](./img/p12_point_prompt.png){ width="600" }

üìä *Ejemplo de imagen + box prompt*   
![Setup](./img/p12_box_prompt.png){ width="600" }

**Resultados ‚Äî Pretrained SAM (Point Prompts)**

| M√©trica | Media | Desviaci√≥n est√°ndar |
|----------|--------|---------------------|
| IoU | 0.5291 | ¬± 0.3214 |
| Dice | 0.6220 | ¬± 0.3377 |
| Precision | 0.8193 | ‚Äî |
| Recall | 0.5885 | ‚Äî |

**Resultados ‚Äî Pretrained SAM (Box Prompts)**

| M√©trica | Media | Desviaci√≥n est√°ndar |
|----------|--------|---------------------|
| IoU | 0.7230 | ¬± 0.2088 |
| Dice | 0.8156 | ¬± 0.1985 |
| Precision | 0.8476 | ‚Äî |
| Recall | 0.8106 | ‚Äî |

üìä *Distribuci√≥n IoU - Dice - Precision - Recall*   
![Setup](./img/p12_distribucion.png){ width="600" }


### 4. Creaci√≥n del Dataset y DataLoaders
Para entrenar de forma eficas al modelo, fue necesario crear una clase personalizada llamada `FloodSegmentationDataset(Dataset)`. Esta clase encapsula todo el preprocesamiento requerido por SAM y a su vez organiza los datos de forma que puedan ser utilizados por un DataLoader de PyTorch.

#### 4.1 Redimensionamiento
SAM usa internamente un tama√±o de procesamiento est√°ndar de 1024x1024 p√≠xeles. Debido a esto, todas las imagenes y sus m√°scaras asociadas se deben redimensionar a este tama√±o fijo antes de hacer cualquier transformaci√≥n. De esta forma se asegura que todas las muestras sean compatibles con el image encoder del modelo, se puedan crear batches y el proceso tenga coordenadas coherentes.

#### 4.2 Data augmentation con Albumentations
Dado que el dataset no es muy grande, se incorporaron algunas t√©cnicas de data augmentation para mejorar la capacidad de generalizaci√≥n del modelo. Todo esto se aplica luego del redimensionamiento, as√≠ la imagen y la m√°scara mantienen las mismas dimensiones.
Gracias a estas t√©cnicas, el modelo logra adaptarse mejor a im√°genes con iluminaci√≥n, √°ngulos o condiciones atmosf√©ricas variables.

#### 4.3 Generaci√≥n autom√°tica de prompts
SAM necesita un prompt como entrada. Para cada ejemplo se automatiz√≥ la creaci√≥n de prompts. 
- `prompt_type='point'`: elige un punto aleatorio dentro de la regi√≥n de agua identificada en la m√°scara.
- `prompt_type='box'`: calcula una bounding box a partir de la m√°scara que encierre la regi√≥n segmentada.

El uso de este mecanismo permite entrenar el modelo usando point prompts y box prompts.

#### 4.4 Definici√≥n de collate_fn personalizado
SAM maneja prompts como estructuras heterog√©neas lo que impide usar el collatefn est√°ndar de PyTorch. Para resolver esto se defini√≥ uno personalizada que agrupara im√°genes y m√°scaras, conservara los prompts como una lista y mantuviera el tama√±o original de cada imagen para reescalar las predicciones durante la evaluaci√≥n.
Usando este collate_fn es posible trabajar con batches sin perder informaci√≥n variable que cada prompt pueda contener.

### 5. Funciones de p√©rdida y configuraci√≥n de fine-tuning
Se us√≥ una **p√©rdida combinada (BCE + Dice)**.  
Para el fine-tuning del modelo:

- Se carg√≥ nuevamente SAM en `sam_finetune`.
- Se **congelaron** los par√°metros de `image_encoder` y `prompt_encoder`
- Se dej√≥ **entrenable solo el `mask_decoder`**, para adaptar la etapa de decodificaci√≥n de m√°scaras al dominio espec√≠fico de inundaciones.
- Se us√≥ el optimizador **Adam** con `lr = 1e-4` y un scheduler `StepLR` que reduce la tasa de aprendizaje cada 5 epochs.

### 6. Entrenamiento y validaci√≥n
Se entren√≥ durante **15 epochs**. En cada iteraci√≥n:

- Se calcul√≥ el embedding de la imagen (sin gradientes).
- Se proces√≥ el prompt.
- Se decodific√≥ la m√°scara (256x256).
- Se calcul√≥ la p√©rdida y el IoU.

Se guard√≥ el mejor modelo (`sam_finetuned_best.pth`) basado en la mayor m√©trica de validaci√≥n.

üìä *Training y Validation para Loss y para IoU*   
![Setup](./img/p12_loss_iou.png){ width="600" }

### 7. Evaluaci√≥n post fine-tuning
El modelo fine-tuneado se evalu√≥ sobre el conjunto de validaci√≥n, mostrando mejoras consistentes en todas las m√©tricas (IoU, Dice, precision, recall).  

Se compararon las m√©tricas promedio del modelo:

- **Pretrained SAM** vs **SAM fine-tuneado**

M√©tricas consideradas:

- IoU medio + desviaci√≥n est√°ndar
- Dice medio
- Precisi√≥n y recall medios

Adem√°s de los valores num√©ricos, se generaron:

- Histogramas que comparan las distribuciones de IoU, Dice, Precision y Recall antes y despu√©s del fine-tuning.
- Un **bar chart** resumiendo el valor medio de cada m√©trica para ambos modelos.

**Comparaci√≥n ‚Äî Pretrained vs Fine-tuned SAM**

| M√©trica | Pretrained | Fine-tuned | Mejora (%) |
|----------|-------------|-------------|-------------|
| IoU | 0.5291 | 0.7311 | +38.18% |
| Dice | 0.6220 | 0.8305 | +33.52% |
| Precision | 0.8193 | 0.8843 | +7.94% |
| Recall | 0.5885 | 0.7995 | +35.84% |

üìä *Comparativa modelo pre-trained vs fine-tuned*   
![Setup](./img/p12_pretrained_finetuned.png){ width="600" }

üìä *Pre-trained vs fine-tuned performance*   
![Setup](./img/p12_pretrained_finetuned2.png){ width="600" }

---

## Evidencias
üìì **Notebook**
  
- [Archivo local del Notebook](./notebook/practica12.ipynb)  
- [Abrir en Google Colab](https://colab.research.google.com/drive/1OWp82yZskVM5HnT-zuLUVmrw_a0sPf_z?usp=sharing) 

---

## Reflexi√≥n

### ¬øPor qu√© el pretrained SAM puede fallar en detectar agua?
SAM fue entrenado en im√°genes generales y no especializadas. El agua en inundaciones presenta alta variabilidad: reflejos, texturas turbias, sombras y objetos flotantes confunden al modelo. SAM es un modelo generalista. El agua grisacea incluso puede ser confundida con asfalso o con tierra h√∫meda. Los reflejos pueden simular delimitaciones rigidas de objetos s√≥lidos. Los *prompts* simples (como un punto o una caja) no siempre son suficientes para delimitar correctamente la regi√≥n de agua.

### ¬øQu√© componentes se fine-tunearon y por qu√©?
Solo el **mask decoder**. El **image encoder** y el **prompt encoder** se congelaron porque ya capturan representaciones visuales generales. De esta forma al fine-tunear solo el decodificador se permite adaptar el modelo a las caracter√≠sticas espec√≠ficas del dominio y el caso concreto sin destruir su conocimiento general.

### ¬øC√≥mo se comparan point prompts vs box prompts?
- **Point prompts:** √∫tiles cuando el agua ocupa una zona clara y delimitada.
- **Box prompts:** m√°s robustos cuando el agua es extensa o irregular.  
En este caso, los box prompts tendieron a obtener IoU ligeramente superiores, aunque el fine-tuning con point prompts mejor√≥ bastante su desempe√±o.

### ¬øQu√© mejoras se observaron tras el fine-tuning?
- Bordes del agua m√°s definidos.
- Menos falsos positivos en sombras o carreteras.
- Mejor detecci√≥n de peque√±as zonas de agua.
- M√°s consistencia entre diferentes tipos de im√°genes.  
Las m√©tricas IoU y Dice aumentaron visiblemente, y las m√°scaras mostraron mayor coherencia espacial.


### ¬øQu√© desaf√≠os espec√≠ficos presenta la segmentaci√≥n de agua en inundaciones?
- **Reflejos:** reflejos del cielo y edificios enga√±an al modelo.
- **Sombras:** zonas oscuras no siempre son agua.
- **Objetos flotantes:** cortan la continuidad del √°rea inundada.
- **Colores variables:** desde azul a marr√≥n oscuro.
- **Bordes difusos:** la transici√≥n entre agua y tierra no siempre es clara.  
El modelo debe aprender a distinguir estos patrones para lograr segmentaciones confiables.

---

## Referencias

- [Kirillov, A., Mintun, E., et al. (2023). *Segment Anything*. Meta AI Research.](https://arxiv.org/abs/2304.02643)

- [Repositorio oficial de Segment Anything (Meta AI) ‚Äì GitHub](https://github.com/facebookresearch/segment-anything)

- [Dataset: *Flood Area Segmentation* ‚Äì Kaggle (Faizal Karim)](https://www.kaggle.com/datasets/faizalkarim/flood-area-segmentation)

- [PyTorch Documentation ‚Äì Dataset, DataLoader y Autograd](https://pytorch.org/docs/stable/data.html)

- [Albumentations: Efficient Image Augmentation Library](https://albumentations.ai/docs/)

- [OpenCV-Python Documentation ‚Äì Image Processing Reference](https://docs.opencv.org/4.x/)
