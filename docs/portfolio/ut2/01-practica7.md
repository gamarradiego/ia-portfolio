---
title: "Pr√°ctica 7 - Perceptron a redes neuronales"
date: 2025-09-16
---

# Pr√°ctica 7 - Perceptron a redes neuronales

## Contexto
Comenzar a trabajar con redes neuronales contrastando su potencial con el del perceptron simple. La idea es plantear problemas que no pueden ser resueltos por el perceptron y requieren mayor complejidad.

## Objetivos
- Probar la resoluci√≥n de problemas que no se pueden resolver con el perceptron simple.
- Trabajar con redes multicapas con MLPClassifier de scikit-learn.
- Implementar redes neuronales que utilicen TensorFlow y PyTorch Lightning.

## Actividades (con tiempos estimados)

| Actividad                          | Tiempo | Resultado esperado                                      |
|------------------------------------|:------:|---------------------------------------------------------|
| Perceptr√≥n simple (AND/OR/XOR)     |  35m   | Resoluci√≥n de compuertas l√≥gicas y comprobaci√≥n l√≠mite (XOR) |
| MLPClassifier en scikit-learn      |  50m   | Superficie de decisi√≥n no lineal + accuracy en dataset real |
| TensorFlow (modelo denso)          |  60m   | Modelo entrenado (95‚Äì97% accuracy) + curvas de loss/accuracy |
| PyTorch Lightning                  |  60m   | Modelo entrenado y evaluado con DataLoader y m√©tricas comparables |
| Comparaci√≥n de matrices de confusi√≥n |  20m   | An√°lisis conjunto de errores y aciertos de los 3 frameworks |

## Desarrollo

En esta etapa se abordaron distintos enfoques de redes neuronales, desde un perceptr√≥n simple hasta implementaciones m√°s complejas en **scikit-learn**, **TensorFlow** y **PyTorch Lightning**, con el objetivo de analizar sus capacidades de clasificaci√≥n y comparar resultados.

### 1. Perceptr√≥n simple y l√≥gica booleana
Se comenz√≥ resolviendo problemas de **l√≥gica booleana** (ej: compuertas AND y OR) utilizando un perceptr√≥n simple.  
El modelo permite encontrar **soluciones lineales**, pero se comprob√≥ que **no puede resolver el problema del XOR**, dado que no es linealmente separable.

üìå *Implementaci√≥n del perceptr√≥n simple*

```python hl_lines="2 6" linenums="1"
# Funci√≥n perceptr√≥n b√°sica
def perceptron(x1, x2, w1, w2, bias):
    return 1 if (w1*x1 + w2*x2 + bias) >= 0 else 0
```

üìä *Imagen de la superficie de decisi√≥n: l√≠nea recta del perceptr√≥n simple*

![XOR con perceptron](./img/perceptron_xor.png){ width="600" }

---

### 2. MLPClassifier de scikit-learn
A continuaci√≥n, se construy√≥ una **red multicapa (MLP)** con `MLPClassifier` de *scikit-learn* para resolver el problema del XOR.  
Este enfoque s√≠ logra separar correctamente las clases, mostrando una **superficie de decisi√≥n no lineal (curva)**.

üìå *Definici√≥n y entrenamiento del MLPClassifier*

```python hl_lines="2 6" linenums="1"
# Primero: resolver XOR que era imposible con perceptr√≥n
X_xor = np.array([[0,0], [0,1], [1,0], [1,1]])
y_xor = np.array([0, 1, 1, 0])


hidden_sizes = (6,) # ¬øcu√°ntas neuronas ocultas?
# Crear MLP
mlp_xor = MLPClassifier(
    hidden_layer_sizes=hidden_sizes,
    activation='relu',           # relu, logistic, tanh
    solver='adam',
    random_state=42,
    max_iter=2000
)

# Entrenar y evaluar
mlp_xor.fit(X_xor, y_xor)
y_pred_xor = mlp_xor.predict(X_xor)

print("üéØ MLP resuelve XOR:")
print("x1 | x2 | esperado | predicci√≥n | ‚úì")
for i in range(len(X_xor)):
    ok = "‚úì" if y_pred_xor[i] == y_xor[i] else "‚úó"
    print(f" {X_xor[i][0]} |  {X_xor[i][1]} |    {y_xor[i]}     |     {y_pred_xor[i]}      | {ok}")
```
üìä *Arquitectura de la MLP para resolver XOR*

![XOR con perceptron](./img/red_mlp_xor.png){ width="600" }

üìä *Comparativa superficie de decisi√≥n curva vs. l√≠nea recta del perceptr√≥n simple*

![XOR con perceptron](./img/superficies_xor.png){ width="600" }

El modelo luego fue probado en un **dataset real**, alcanzando un **test accuracy de 95.7%**.

---

### 3. Red neuronal en TensorFlow
Posteriormente, se implement√≥ un modelo m√°s profesional en **TensorFlow**, con la siguiente arquitectura:

- Dos capas densas de **128 neuronas** cada una, con activaci√≥n **ReLU**.  
- Una capa de salida con **activaci√≥n sigmoide** (clasificaci√≥n binaria).  
- Entrenado durante **30 √©pocas**, con **batch size de 32**.  
- Funci√≥n de p√©rdida: **binary crossentropy**.  
- Optimizador: **Adam**.  

El modelo alcanz√≥ entre **94% y 97% de test accuracy**, con aproximadamente **19.329 par√°metros entrenables**.

üìå *Definici√≥n del modelo en TensorFlow*

```python hl_lines="2 6" linenums="1"
# Crear modelo Sequential
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # salida binaria
])

# Compilar modelo
model.compile(
    optimizer='adam',              # adam, sgd, rmsprop
    loss='binary_crossentropy',                   # binary_crossentropy
    metrics=['accuracy']
)

# Entrenar
print("Entrenando red neuronal...")
history = model.fit(
    X_train, y_train,
    epochs=30,                   # n√∫mero de epochs
    batch_size=32,               # tama√±o de batch
    validation_data=(X_test, y_test),
    verbose=1
)

# Evaluar
train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
```

üìä *Gr√°ficas de training/validation loss y accuracy*

![Gr√°ficas para TensorFlow](./img/grafica_tensorflow.png){ width="600" }

En la gr√°fica de **loss**, se observa que el **validation loss baja de forma similar al training loss**, lo que indica **ausencia de overfitting significativo**. A partir de la √©poca 17-18 se ve un estancamiento y a partir de la 20-25 aparece un **ligero ascenso**, posible inicio de sobreajuste.  
En la gr√°fica de **accuracy**, se aprecia un **gap de ~5% entre training y validation accuracy**, dentro de lo esperable.

---

### 4. Modelo en PyTorch Lightning
Luego se implement√≥ un modelo en **PyTorch Lightning**, con arquitectura:

- Dos capas ocultas:  
  - **64 neuronas (ReLU)**  
  - **32 neuronas (ReLU)**  
- Capa de salida con tantas neuronas como clases.  
- Optimizador: **Adam**.  
- Funci√≥n de p√©rdida: **crossentropy**.

üìå *Definici√≥n de la clase para el modelo con Pytorch Lightning*

```python hl_lines="2 6" linenums="1"
class SimpleNet(pl.LightningModule):
    def __init__(self, input_size, hidden_size=64, num_classes=20):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(True),                    # ReLU con inplace
            nn.Linear(hidden_size, 32),     # segunda capa oculta
            nn.ReLU(True),
            nn.Linear(32, num_classes)
        )

    def forward(self, x):
        return self.network(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.functional.cross_entropy(y_hat, y)
        self.log('train_loss', loss)
        return loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.001)

    def test_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.functional.cross_entropy(y_hat, y)

        # Calcular accuracy
        preds = torch.argmax(y_hat, dim=1)
        acc = torch.sum(preds == y).float() / len(y)

        # Logging
        self.log('test_loss', loss)
        self.log('test_acc', acc)
        return loss
```

üìä *Resultados*

| Test metric | DataLoader 0           |
|-------------|------------------------|
| test_acc    | 0.9333333373069763     |
| test_loss   | 0.17134471237659454    |

El modelo fue entrenado y evaluado con datasets preparados en `DataLoader`. Se obtuvieron resultados comparables a TensorFlow, confirmando la robustez de ambas implementaciones.

---

### 5. Comparaci√≥n final
Finalmente, se generaron y compararon las **matrices de confusi√≥n** de los tres modelos (scikit-learn, TensorFlow y PyTorch Lightning).

üìä *Matriz de confusi√≥n para cada modelo*

![Matrices comparativa](./img/matrices_confusion_comparativa.png){ width="800" }

El an√°lisis de las matrices permiti√≥ identificar:
- **Diagonal principal (TP + TN):** aciertos.  
- **Diagonal secundaria (FP + FN):** errores.  
- Diferencias menores en falsos positivos y falsos negativos entre frameworks.  

En general, los tres modelos alcanzaron un desempe√±o similar, con ligeras variaciones en el balance de errores. Se ve un mejor desempe√±o en Sklearn MLP en cuanto a falsos negativos.

---

## Evidencias
üìì **Notebook**
  
- [Archivo local del Notebook](./notebook/practica7.ipynb)  
- [Abrir en Google Colab](https://colab.research.google.com/drive/1jG3t5Y_zv82SD_QC8rQFWiuQ4MkRDdir?usp=sharing)

## Reflexi√≥n

Durante esta pr√°ctica pude avanzar desde la comprensi√≥n del **perceptr√≥n simple** hasta la experimentaci√≥n con modelos m√°s complejos en **scikit-learn, TensorFlow y PyTorch Lightning**.  
Aprend√≠ que las limitaciones del perceptr√≥n radican en su incapacidad para resolver problemas no linealmente separables, lo cual se hace evidente en el caso del operador l√≥gico XOR. A partir de ah√≠, incorporar **capas ocultas** y **funciones de activaci√≥n no lineales** permite aumentar la capacidad de representaci√≥n del modelo.  

Como pr√≥ximos pasos me interesa profundizar en t√©cnicas de **regularizaci√≥n** (dropout, weight decay), la exploraci√≥n de **convoluciones** para otros tipos de datos, y experimentar con **early stopping** (y otros callbacks) para controlar el sobreajuste.

---

### Preguntas de reflexi√≥n

- **¬øPor qu√© AND, OR y NOT funcionaron pero XOR no?**  
  Porque son linealmente separables y pueden resolverse con una sola l√≠nea recta, mientras que XOR requiere al menos dos l√≠neas o fronteras, no se puede separar con una recta en el plano.

- **¬øCu√°l es la diferencia clave entre los pesos de AND vs OR?**  
  En AND el umbral es m√°s alto: se necesitan entradas fuertes para activar la salida. En OR el umbral es menor: basta con que una entrada sea 1.

- **¬øQu√© otros problemas del mundo real ser√≠an como XOR?**  
  Casos de exclusi√≥n mutua. Situaciones donde se puede elegir una opci√≥n u otra pero no ambas al mismo tiempo. Ejemplo: un sem√°foro que solo puede estar en verde **o** en rojo, pero nunca en los dos a la vez.

- **¬øPor qu√© sklearn MLP puede resolver XOR pero un perceptr√≥n no?**  
  Porque el MLP tiene varias capas y puede combinar varias ‚Äúl√≠neas de decisi√≥n‚Äù para generar superficies no lineales (curvas como la que se ve en el gr√°fico). El perceptr√≥n solo puede generar una recta.

- **¬øCu√°l es la principal diferencia entre TensorFlow/Keras y sklearn MLP?**  
  TensorFlow da mucho m√°s control sobre arquitectura, entrenamiento y optimizaci√≥n, mientras que sklearn MLP es m√°s limitado pero r√°pido de usar.

- **¬øPor qu√© TensorFlow usa epochs y batch_size mientras sklearn MLP no?**  
  Porque TensorFlow entrena expl√≠citamente en lotes (batch gradient descent). En sklearn, el proceso est√° m√°s abstra√≠do y entrena todo de forma m√°s autom√°tica.

- **¬øCu√°ndo usar√≠as sigmoid vs relu como funci√≥n de activaci√≥n?**  
  `sigmoid` en salidas binarias (da probabilidades entre 0 y 1). `ReLU` en capas ocultas porque es m√°s eficiente y evita problemas de gradiente.

- **¬øQu√© ventaja tiene PyTorch Lightning sobre TensorFlow puro?**  
  Permite escribir menos c√≥digo repetitivo (boilerplate), organizando entrenamiento, validaci√≥n y prueba de manera clara y concisa.

- **¬øPor qu√© PyTorch Lightning separa training_step y test_step?**  
  Porque durante entrenamiento hay backpropagation, mientras que en test solo se eval√∫a con m√©tricas. Son procesos distintos. En training_step se define qu√© pasa en cada batch durante el entrenamiento. Se calcula la predicci√≥n, la p√©rdida, se devuelve el loss para as√≠ hacer backpropagation (y optimizar pesos). En el test_step se define qu√© pasa en cada batch durante el test, o sea, con el modelo ya entrenado. No hay devoluci√≥n de loss para hacer backpropagation ya que no hay actualizaci√≥n de par√°metros, solo hay medici√≥n.

- **¬øCu√°l framework elegir√≠as para cada escenario?**  
  Prototipo r√°pido: **scikit-learn MLP**  
  Modelo en producci√≥n: **TensorFlow/Keras**  
  Investigaci√≥n avanzada: **PyTorch Lightning**

- **¬øPor qu√© el error `mat1 and mat2 shapes cannot be multiplied` es com√∫n en PyTorch?**  
  Porque la forma (dimensi√≥n) de los datos de entrada no coincide con lo que espera la primera capa `Linear`. Hay que alinear features con neuronas.

- **¬øQu√© significa `deterministic=True` en PyTorch Lightning Trainer?**  
  Que se busca reproducibilidad: fija el comportamiento aleatorio para que cada corrida d√© los mismos resultados.

- **¬øPor qu√© TensorFlow muestra curvas de loss y val_loss durante entrenamiento?**  
  Para monitorear posibles s√≠ntomas de overfitting. Si la curva de validaci√≥n empieza a subir mientras la de entrenamiento baja, hay overfitting.

- **¬øCu√°l es la diferencia entre `trainer.test()` y `trainer.predict()` en PyTorch Lightning?**  
  `test()` devuelve m√©tricas (loss, accuracy, etc.). `predict()` devuelve predicciones sobre los datos, sin calcular m√©tricas.

- **¬øPor qu√© sklearn MLP es m√°s f√°cil pero menos flexible?**  
  Porque oculta los detalles del entrenamiento, lo cual simplifica el uso, pero a cambio se pierde control fino sobre la arquitectura y el proceso.


## Referencias
- [Documentaci√≥n de scikit-learn ‚Äì MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [Tutorial de TensorFlow ‚Äì Redes Neuronales](https://www.tensorflow.org/tutorials/keras/classification)
- [Documentaci√≥n de PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)
- [Documentaci√≥n de PyTorch ‚Äì torch.nn](https://pytorch.org/docs/stable/nn.html)

---